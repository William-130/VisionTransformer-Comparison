# Vision Transformer Comparison: Swin vs ViT

Proyek perbandingan performa dua model Vision Transformer (Swin Transformer dan ViT) pada dataset Indonesian Food Classification dengan 5 kelas.

## ğŸ“‹ Deskripsi

Tugas eksplorasi ini membandingkan:

- **Swin Transformer**: Hierarchical transformer dengan shifted window attention
- **Vision Transformer (ViT)**: Pure transformer architecture untuk computer vision (ViT-Base/16)

Kedua model menggunakan pre-trained weights dari ImageNet dan di-fine-tune pada dataset Indonesian Food.

## ğŸ—‚ï¸ Struktur Project

```
transformer_explore/
â”œâ”€â”€ dataset/                   # Dataset Indonesian Food
â”‚   â”œâ”€â”€ train.csv              # Label file
â”‚   â””â”€â”€ train/                 # Image files
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ data_preparation.py    # Data loading dan preprocessing
â”‚   â”œâ”€â”€ train_swin.py          # Training Swin Transformer
â”‚   â”œâ”€â”€ train_vit.py           # Training Vision Transformer (ViT)
â”‚   â”œâ”€â”€ evaluate.py            # Evaluasi model dan metrics
â”‚   â””â”€â”€ visualize.py           # Visualisasi hasil
â”œâ”€â”€ models/                    # Saved model weights
â”œâ”€â”€ outputs/                   # Hasil eksperimen
â”‚   â”œâ”€â”€ figures/              # Visualisasi dan plot
â”‚   â””â”€â”€ results/              # Metrics dan logs
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                 # Dokumentasi ini
```

## ğŸš€ Setup dan Instalasi

### 1. Buat Virtual Environment

```powershell
# Buat virtual environment
python -m venv venv

# Aktivasi virtual environment
.\venv\Scripts\Activate.ps1

# Jika ada error execution policy, jalankan:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### 2. Install Dependencies

```powershell
pip install -r requirements.txt
```

### 3. Verifikasi Dataset

Pastikan struktur dataset sudah benar:

```
dataset/
â”œâ”€â”€ train.csv          # File dengan kolom: filename, label
â””â”€â”€ train/            # Folder berisi semua gambar
```

## ğŸ“Š Cara Menjalankan

### Step 1: Eksplorasi Data

```powershell
python src/data_preparation.py
```

Output:

- Distribusi kelas
- Sample visualisasi
- Statistik dataset

### Step 2: Training Swin Transformer

```powershell
python src/train_swin.py
```

Model yang digunakan: `swin_tiny_patch4_window7_224` (pre-trained ImageNet)

### Step 3: Training Vision Transformer (ViT)

```powershell
python src/train_vit.py
```

Model yang digunakan: `vit_base_patch16_224` (pre-trained ImageNet)

### Step 4: Evaluasi dan Perbandingan

```powershell
python src/evaluate.py
```

Output:

- Accuracy, Precision, Recall, F1-Score
- Confusion Matrix
- Inference Time
- Parameter Count

### Step 5: Visualisasi Hasil

```powershell
python src/visualize.py
```

Output:

- Learning curves
- Confusion matrices
- Comparison tables
- Sample predictions

## ğŸ“ˆ Metrik Evaluasi

Setiap model dievaluasi berdasarkan:

1. **Jumlah Parameter**

   - Total parameters
   - Trainable parameters
   - Model size (MB)

2. **Performance Metrics**

   - Accuracy
   - Precision (per-class & average)
   - Recall (per-class & average)
   - F1-Score (per-class & average)
   - Confusion Matrix

3. **Inference Time**
   - Average time per image (ms)
   - Throughput (images/second)
   - Total test set time

## âš™ï¸ Konfigurasi Training

### Hyperparameters

#### Swin Transformer:
- **Input Size**: 224x224
- **Batch Size**: 8
- **Epochs**: 10
- **Optimizer**: AdamW
- **Learning Rate**: 5e-6
- **Weight Decay**: 0.1
- **Scheduler**: CosineAnnealingLR

#### Vision Transformer (ViT):
- **Input Size**: 224x224
- **Batch Size**: 4
- **Epochs**: 10
- **Optimizer**: AdamW
- **Learning Rate**: 5e-5
- **Weight Decay**: 0.1
- **Scheduler**: CosineAnnealingLR

### Data Augmentation

- Random Horizontal Flip
- Random Rotation (Â±10Â°)
- Color Jitter
- Normalization (ImageNet stats)

## ğŸ’» Hardware

Spesifikasi yang digunakan:

- GPU: NVIDIA GeForce RTX 3050 Laptop GPU (4GB)
- CPU: Intel Core i5-11400H
- RAM: 16 GB
- OS: Windows 11

## ğŸ“ Hasil

Hasil lengkap tersimpan di folder `outputs/`:

- `outputs/figures/`: Semua visualisasi
- `outputs/results/`: Metrics dalam format CSV dan JSON
- `models/`: Model weights (best & last checkpoint)

## ğŸ” Reproducibility

Untuk hasil yang reproducible:

- Random seed: 42 (set di semua script)
- Gunakan dependencies dari `requirements.txt`
- Jalankan dengan configuration yang sama

## ï¿½ Hasil Eksperimen

### Model Performance Summary:

| Model | Parameters | Size | Accuracy | Precision | Recall | F1-Score | Inference Speed |
|-------|-----------|------|----------|-----------|--------|----------|-----------------|
| **Swin Transformer** | 27.5M | 105 MB | 97.75% | 97.74% | 97.74% | 97.73% | 1,754 img/s |
| **Vision Transformer (ViT)** | 85.8M | 327 MB | **98.65%** | 98.67% | 98.64% | 98.64% | 1,294 img/s |

### Key Findings:

- âœ… **ViT Base** mencapai akurasi tertinggi (98.65%)
- âœ… **Swin Transformer** 3x lebih ringan dan 35% lebih cepat
- âœ… Kedua model sangat baik untuk Indonesian Food Classification (>97% accuracy)
- âœ… Trade-off: ViT menang 0.9% akurasi, Swin unggul di efisiensi

## ğŸ“š Referensi

1. **Vision Transformer (ViT)**: [Dosovitskiy et al., 2021] - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
2. **Swin Transformer**: [Liu et al., 2021] - Swin Transformer: Hierarchical Vision Transformer using Shifted Windows
3. **PyTorch Image Models (timm)**: https://github.com/huggingface/pytorch-image-models

## ğŸ‘¨â€ğŸ“ Author

- **Nama**: William Chan
- **NIM**: 122140130
- **Mata Kuliah**: Deep Learning
- **Semester**: Ganjil 2025/2026

## ğŸ“„ License

Proyek ini dibuat untuk keperluan tugas akademik.
